### ğŸ¯ Quick Navigation

- [ğŸ“š Key Frameworks & Models](#-key-frameworks--models) - BSIMM, STRIDE, DREAD, PASTA
- [ğŸ” Security Testing](#-security-testing) - Testing types and methodologies
- [âš™ï¸ SDL Integration](#ï¸-sdl-integration) - Agile security and requirement types
- [ğŸ” Core Security Principles](#-core-security-principles) - Access control and data protection
- [ğŸš¨ Common Vulnerabilities](#-common-vulnerabilities) - Attack types and countermeasures
- [ğŸ“– Essential Terminology](#-essential-terminology) - Key terms and definitions
- [ğŸ¯ Course Overview](#-course-overview) - Core competencies and exam focus

---

## ğŸ“š Key Frameworks & Models

### ğŸ—ï¸ BSIMM (Building Security In Maturity Model)

**Purpose**: Studies real-world software security initiatives for benchmarking

**Four Domains**:

- ğŸ›ï¸ **Governance**: Strategy, compliance, training programs
- ğŸ§  **Intelligence**: Attack models, security features, standards research
- ğŸ”¨ **SSDL Touchpoints**: Hands-on security activities (code review, testing)
- ğŸš€ **Deployment**: Configuration management, vulnerability management

**Key Distinction**: BSIMM is **descriptive** (what organizations actually do) vs SAMM is **prescriptive** (what you should do)

### âš”ï¸ STRIDE Threat Modeling

- **S**poofing: Identity impersonation attacks
- **T**ampering: Unauthorized data modification
- **R**epudiation: Denial of performed actions
- **I**nformation Disclosure: Unauthorized data access
- **D**enial of Service: Service availability attacks
- **E**levation of Privilege: Unauthorized access escalation

**Application Methods**:

- ğŸ” **STRIDE-per-element**: Analyze each individual component/object
- âš™ï¸ **STRIDE-per-process**: Focus only on processes
- ğŸŒ‰ **STRIDE-per-trust-boundary**: Analyze security boundary crossings
- ğŸ”„ **STRIDE-per-interaction**: Focus on data flows between components

### ğŸ’¥ DREAD Risk Scoring

**Ternary Scale**: High=3, Medium=2, Low=1

- **D**amage: Potential impact severity
- **R**eproducibility: How easily attack can be repeated
- **E**xploitability: Difficulty of executing the attack
- **A**ffected users: Scope and number of impacted users
- **D**iscoverability: How easy vulnerability is to find

**Total Score Interpretation**:

- 13-15 points = High Risk
- 8-12 points = Medium Risk
- 5-7 points = Low Risk

### ğŸ”¬ PASTA (Process for Attack Simulation and Threat Analysis)

**Seven-Stage Methodology**:

1. **Define Objectives** - Business and security requirements
2. **Define Technical Scope** - Application boundaries and components
3. **Application Decomposition** - Break down architecture and data flows
4. **Threat Analysis** - Identify potential threats and attack vectors
5. **Vulnerability and Weakness Analysis** - **Design flaw analysis occurs here**
6. **Attack Modeling** - Develop specific attack scenarios
7. **Risk and Impact Analysis** - Evaluate business impact and likelihood

### ğŸ—ï¸ Microsoft Threat Modeling

**Four-Step Process**:

1. **Diagram** - Create data flow diagrams
2. **Identify** - Find threats using STRIDE
3. **Mitigate** - Apply countermeasures
4. **Validate** - Verify threat mitigation effectiveness

### ğŸ¢ OCTAVE (Operationally Critical Threat, Asset, and Vulnerability Evaluation)

**Three Phases**:

- **Phase 1**: Build asset-based threat profiles
- **Phase 2**: Identify infrastructure vulnerabilities
- **Phase 3**: Develop security strategy and plans

### ğŸ¯ TRIKE

**Risk-based approach**:

- **Requirements Model** - Define security requirements
- **Implementation Model** - Analyze system implementation
- **Risk Model** - Calculate risk levels for threats


### ğŸ“š SDL Phases

- **SDL A1:** Security Assessment (Discovery Phase)
	- Identify product risk profile (security changes needed to cater to different markets)
	- SDL project outline (map SDL to dev schedule)
	- Applicable laws and regulations
	- Accuracy of the threat profile (customers misuse and change things)
	- Certification requirements
	- List of third-party software
	- Metric template
	- Privacy Impact Assessment plan
		- Summary of the Legislation
		- Required Process Steps
		- Technologies and Techniques
		- Additional Resources
- **SDL A2:** Architecture
	- Identification of business requirements and risk
	- Data Flow Diagram
	- Threat modeling via STRIDE / DREAD / risk = likelihood x impact
		- Identify security objectives
		- Survey the application
		- Decompose it
		- Identify threats
		- Identify vulnerabilities 
	- Risk mitigation
	- Policy compliance analysis
- **SDLA3:** Design and Development 
	- Analysis of policy compliance (review)
	- Create the test plan documentation
	- Static analysis
	- Update your threat model
	- Design security analysis and review
	- Privacy implementation assessment 
	- 1974 UVA Saltzer/Schroeder
- **SDLA4:** Design and Development (readiness)
	- Policy compliance analysis
	- Security test case execution
	- Static analysis
	- Dynamic analysis
	- Fuzz testing
	- Manual code review
	- Privacy validation and remediation
- **SDLA5:** Ship
	- Final security review
	- Vulnerability scan
	- Penetration testing
	- Open source licensing review
	- Final security review
	- Final privacy review
	- Customer engagement framework
- **PRSA1:** External Vulnerability Disclosure Response
- **PRSA2:** Third-Party Reviews
- **PRSA3:** Post-Release Certifications
- **PRSA4:** Internal Review for New product Combinations or Cloud Deployments
- **PRSA5:** Security Architectural Reviews and Tool-Based Assessments of Current, Legacy, and M&A Products and Solutions
	- External vulnerability disclosure response process
	- Post-release certifications
	- Third-party security reviews
	- Security strategy and process for legacy code, M&A, and EOL plans

---

## ğŸ” Security Testing

### ğŸ“Š Analysis Methods

|Method|Description|When to Use|
|---|---|---|
|ğŸ” **Static Analysis**|Code examination without execution|Early development, code review|
|â–¶ï¸ **Dynamic Analysis**|Testing while program executes|Runtime behavior, integration testing|
|ğŸ“– **White-box**|Full access to source code/docs|Comprehensive internal testing|
|ğŸ”˜ **Gray-box**|Limited internal knowledge|Hybrid approach|
|âš« **Black-box**|External perspective only|User experience testing|

### ğŸ§ª Testing Categories

- ğŸ¯ **Functional Testing**: Validates application requirements compliance
- ğŸ”§ **Unit Testing**: Individual component testing
- ğŸ”— **Integration Testing**: Component interaction testing
- ğŸ”„ **Regression Testing**: Ensures changes don't break existing functionality

### ğŸ› ï¸ Security Testing Tools

- **SonarQube**: Static code analysis (SAST)
- **OWASP ZAP**: Dynamic application security testing (DAST)
- **Burp Suite**: Web application security testing

---

## âš™ï¸ SDL Integration

### ğŸƒâ€â™‚ï¸ Agile Security Requirement Types

- ğŸ”„ **Every-sprint Requirements**: Applied continuously (input validation, authentication)
- ğŸª£ **Bucket Requirements**: Triggered by specific technologies (RPC fuzz testing)
- 1ï¸âƒ£ **One-time Requirements**: Implemented once per project (initial architecture)
- âœ… **Final Security Review Requirements**: Pre-release validation activities

### ğŸ“‹ Key SDL Deliverables

- ğŸ“… **SDL Project Outline**: Security milestones integrated with development schedule
- âœ… **Policy Compliance Analysis**: Verification of adherence to organizational security rules
- ğŸ—‚ï¸ **Threat Modeling Artifacts**: Updated documentation with newly identified vulnerabilities
- ğŸ¢ **Security Strategy for M&A**: Framework for integrating acquired products

### ğŸšª Security Gates & Reviews

- **Final Security Review Outcomes**:
    - âœ… **Passed**: All issues resolved, all requirements met
    - âš ï¸ **Passed with exceptions**: Minor acceptable risks remain
    - âŒ **Not passed (escalation)**: Critical issues require escalation
    - â¸ï¸ **Not passed (no escalation)**: Issues exist but not critical

---

## ğŸ” Core Security Principles

### ğŸ›¡ï¸ Access Control Principles

- ğŸ”’ **Principle of Least Privilege**: Users get minimum necessary access
- ğŸ‘¥ **Role-Based Access Control (RBAC)**: Access based on user roles
- ğŸ¤ **Separation of Duties**: Multiple people required for critical tasks
- ğŸ° **Defense in Depth**: Multiple layers of protection

### ğŸ›¡ï¸ Data Protection

- âœ… **Input Validation**: Verify user input meets expected criteria (type, size, range)
- ğŸ”¤ **Output Encoding**: Prevent XSS by encoding special characters (<, >, ", ', &)
- ğŸ’‰ **Parameterized Queries**: Prevent SQL injection by separating code from data
- ğŸ” **Cryptographic Practices**: Use proven algorithms (AES, RSA, SHA-256)

### âš™ï¸ Configuration Security

- ğŸ”§ **System Configuration**: Maintain latest approved versions of all components
- ğŸ‘¤ **Default Account Management**: Disable/remove default credentials immediately
- ğŸŒ **Communication Security**: Encrypt all data in transit (TLS/SSL)

---

## ğŸš¨ Common Vulnerabilities

### ğŸ’‰ Injection Attacks

|Vulnerability|Countermeasure|Implementation|
|---|---|---|
|SQL Injection|Parameterized Queries|Use placeholders, not string concatenation|
|XSS|Output Encoding|Encode <, >, ", ', & characters|
|File Upload|Input Validation|Validate file type, size, content|

### ğŸ”‘ Authentication & Session Issues

- ğŸ”’ **Weak Passwords**: Enforce complexity (8+ chars, upper, number, special)
- â° **Session Management**: Proper timeouts and session handling
- â¬†ï¸ **Privilege Escalation**: Restore proper privileges after exceptions

### ğŸ” Cryptographic Failures

- ğŸ§‚ **Weak Hashing**: Use strong, salted hashing (bcrypt, Argon2, scrypt)
- âš™ï¸ **Default Configurations**: Change all default settings and credentials
- ğŸ”‘ **Key Management**: Proper encryption key storage and rotation

---

## ğŸ“‹ Exam Question Types

### ğŸ­ Scenario-Based Questions (40%)

**Example Pattern**: "A security team discovered..." or "During testing, an analyst found..."

- Real-world application of security concepts
- SDL phase identification and appropriate activities
- Vulnerability remediation strategies

### ğŸ“– Definition & Classification (25%)

**Example Pattern**: "Which framework studies real-world security initiatives?"

- Framework purposes and distinctions
- Requirement type classifications
- Security principle definitions

### ğŸ”§ Technical Implementation (20%)

**Example Pattern**: "How should existing security controls be adjusted?"

- Specific countermeasures for vulnerabilities
- Secure coding practice implementation
- Configuration and remediation steps

### ğŸ”„ Process & Workflow (15%)

**Example Pattern**: "What is the next step in the process?"

- PSIRT workflow sequences
- SDL phase activities
- Incident response procedures

---

## âš ï¸ Critical Exam Tips

### ğŸ” Key Distinctions to Remember

- **BSIMM vs SAMM**: BSIMM studies what organizations do, SAMM prescribes what to do
- **Static vs Dynamic**: Static = no execution, Dynamic = while running
- **White vs Black box**: White = full internal access, Black = external perspective only
- **Every-sprint vs Bucket**: Every-sprint = always required, Bucket = when specific tech used
- **PASTA vs Microsoft**: PASTA has 7 stages, Microsoft has 4 steps (Diagram, Identify, Mitigate, Validate)
- **STRIDE applications**: Per-element (most granular), per-process (processes only), per-trust-boundary (boundaries), per-interaction (data flows)

### ğŸ¯ Keyword Recognition

- "**Real-world initiatives**" â†’ BSIMM
- "**Without executing**" â†’ Static Analysis
- "**All traffic encrypted**" â†’ Communication Security
- "**Default settings**" â†’ Remove/disable default accounts
- "**Easily repeated**" â†’ Reproducibility (DREAD)
- "**Design flaw analysis**" â†’ PASTA Stage 5 (Vulnerability and Weakness Analysis)
- "**Data flow diagram**" â†’ Microsoft Threat Modeling Step 1 (Diagram)
- "**Seven stages**" â†’ PASTA methodology
- "**Four steps**" â†’ Microsoft Threat Modeling

### ğŸš¨ Common Traps

- Don't confuse **remediation** (how to fix) with **detection** (how to find)
- **Final Security Review** needs ALL issues resolved for "Passed" status
- **Bucket requirements** are triggered by technology, not always applied
- **PSIRT workflow**: Fix development comes before customer notification

---

## ğŸ“– Essential Terminology

### ğŸ—ï¸ Frameworks & Standards

- **BSIMM**: Building Security In Maturity Model - studies real-world practices
- **SAMM**: Software Assurance Maturity Model - prescriptive framework
- **STRIDE**: Threat modeling methodology (6 threat categories)
- **DREAD**: Risk scoring system (5 factors)
- **PASTA**: Process for Attack Simulation and Threat Analysis (7 stages)
- **Microsoft Threat Modeling**: 4-step process (Diagram, Identify, Mitigate, Validate)
- **OCTAVE**: Operationally Critical Threat, Asset, and Vulnerability Evaluation
- **TRIKE**: Risk-based threat modeling approach
- **ISO 27001**: Information Security Management Systems standard
- **CVE**: Common Vulnerabilities and Exposures naming system
- **OWASP**: Open Web Application Security Project

### ğŸ”’ Security Concepts

- **SDL**: Security Development Lifecycle
- **SAST**: Static Application Security Testing
- **DAST**: Dynamic Application Security Testing
- **PSIRT**: Product Security Incident Response Team
- **XSS**: Cross-Site Scripting
- **CSRF**: Cross-Site Request Forgery
- **RBAC**: Role-Based Access Control
- **MFA**: Multi-Factor Authentication
- **TLS**: Transport Layer Security
- **AES**: Advanced Encryption Standard

### ğŸ§ª Testing & Development

- **CI/CD**: Continuous Integration/Continuous Deployment
- **DevSecOps**: Development, Security, and Operations integration
- **RACI**: Responsible, Accountable, Consulted, Informed matrix
- **Threat Modeling**: Systematic threat identification process
- **Penetration Testing**: Simulated cyber attack testing
- **Vulnerability Assessment**: Security weakness identification
- **Code Review**: Source code security examination

### ğŸ¯ Key Principles

- **Defense in Depth**: Multiple security layers strategy
- **Least Privilege**: Minimum necessary access principle
- **Fail Safe**: Secure failure mode principle
- **Zero Trust**: Never trust, always verify model
- **Separation of Duties**: Fraud prevention control
- **Input Validation**: User input verification process
- **Output Encoding**: XSS prevention technique
- **Parameterized Queries**: SQL injection prevention method

---
### **HIGH-RISK CONFUSION AREAS**

|**Concept**|**Context Variations**|**Exam Risk**|
|---|---|---|
|**Threat Modeling**|A2: Initial modeling<br>A3: Updated artifacts<br>Tools: STRIDE vs PASTA vs DREAD|**HIGH** - Appears in multiple phases with different purposes|
|**Policy Compliance Analysis**|A2: Initial analysis<br>A3: Updates<br>A4: Compliance review<br>A5: Final analysis|**HIGH** - Same name, different stages|
|**Security Testing**|A3: Test planning<br>A4: Test execution<br>A5: Final testing|**HIGH** - Planning vs execution vs validation|
|**Privacy Activities**|A3: Implementation assessment<br>A4: Validation/remediation<br>A5: Final review|**MEDIUM** - Progressive privacy validation|
|**Risk Mitigation**|A2: Risk mitigation plan<br>A3: Test plans to mitigate risk|**MEDIUM** - Different contexts for same goal|

### **METHODOLOGY DISTINCTIONS**

|**Framework**|**Purpose**|**Key Differentiator**|
|---|---|---|
|**STRIDE**|Threat categorization|Spoofing, Tampering, Repudiation, Information Disclosure, Denial of Service, Elevation of Privilege|
|**PASTA**|Threat modeling process|Process for Attack Simulation and Threat Analysis|
|**DREAD**|Risk scoring|Damage, Reproducibility, Exploitability, Affected users, Discoverability|
|**BSIMM**|Maturity assessment|Studies real-world security initiatives|
|**SAMM**|Prescriptive framework|Software Assurance Maturity Model|

### **TESTING TYPE CONFUSION**

|**Testing Type**|**Information Access**|**When Used**|
|---|---|---|
|**White-box**|Full source code + documentation|A3/A4 - Comprehensive internal testing|
|**Black-box**|No internal knowledge|A4/A5 - External perspective testing|
|**Gray-box**|Limited internal knowledge|A4 - Hybrid approach|
|**Static Analysis**|Code without execution|A3/A4 - SAST tools like SonarQube|
|**Dynamic Analysis**|Runtime execution|A4/A5 - DAST tools, penetration testing|

### **ROLE RESPONSIBILITIES**

|**Role**|**Primary Function**|**Key Activities**|
|---|---|---|
|**Software Security Architect**|Design secure frameworks|Creates secure coding practices, methodologies|
|**Security Champion**|Advocate/promote|Promotes security within development teams|
|**Scrum Master**|Facilitate process|Removes impediments, facilitates ceremonies|
|**Software Developer**|Implement features|Writes code, attends ceremonies|

### **AGILE SDL REQUIREMENTS**

|**Requirement Type**|**Application**|**Example**|
|---|---|---|
|**Every-sprint**|Universal practices|Input validation for all user input|
|**Bucket**|Feature-specific|RPC fuzz testing when RPC implemented|
|**One-time**|Project setup|Initial threat modeling framework|
|**Final review**|Release gates|Comprehensive security assessment|

### **CRITICAL TERMINOLOGY DISTINCTIONS**

- **SDL vs SDLC**: SDL = Security Development Lifecycle, SDLC = Software Development Lifecycle
- **CIA**: Confidentiality, Integrity, Availability (not Central Intelligence Agency)
- **DFD**: Data Flow Diagram (threat modeling artifact)
- **PSIRT**: Product Security Incident Response Team
- **SAST vs DAST**: Static Application Security Testing vs Dynamic Application Security Testing

### **PHASE TRANSITION TRIGGERS**

|**Phase**|**Entry Criteria**|**Exit Criteria**|
|---|---|---|
|**A1â†’A2**|Requirements gathered|Threat profile established|
|**A2â†’A3**|Architecture defined|Risk mitigation plan approved|
|**A3â†’A4**|Test plans created|Design security review complete|
|**A4â†’A5**|Testing executed|Remediation complete|
|**A5â†’PRS**|Final reviews passed|Product shipped|

## ğŸ¯ Course Overview

### Core Competencies

- **4029.2.1**: Security principles, standards, and methods within SDLC
- **4029.2.2**: Software requirements and risk assessment for threat mitigation
- **4029.2.3**: Security test plan documentation and implementation strategies
- **4029.2.4**: Software testing and deployment effectiveness for security/privacy

### Exam Distribution

- ğŸ­ **Threat Modeling & Risk Assessment** (35% - ~21 questions)
- ğŸ”„ **SDL Integration & Security Gates** (25% - ~15 questions)
- ğŸ’» **Secure Coding & Vulnerabilities** (20% - ~12 questions)
- ğŸ§ª **Security Testing Methodologies** (15% - ~9 questions)
- ğŸ“‹ **Standards & Post-Release** (5% - ~3 questions)

---